import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras import layers, models, applications, optimizers, losses, metrics
from tensorflow.keras.callbacks import *
import pandas
import matplotlib.pyplot as plt
import ImageProcessing
import os
import cv2
from os.path import join as pjoin
import math

class MalwareDetectionModels:

    def __init__(self, img_w, img_h, model_name,training_set, validation_set,test_set,loaded):
        self.image_width = img_w
        self.image_height = img_h
        self.model = None
        self.loaded = loaded
        self.last_batch = False
        self.colormap = np.load('/home/user/projects/dataset/colormap/gray_colormap.npy')
        if not loaded:
            if model_name == "M11":
                self.batch_size = 64
                self.model = self.build_m11()
                self.epochs = 30
                self.rate = 0.0001

            self.define_callbacks()
            self.history = self.train_bb_detector(training_set, validation_set)
            self.evaluate_bb_detector(test_set)
            #self.plot_history()
        else:
            self.model = tf.keras.models.load_model('/home/user/projects/GAN_project/RESULTS/saved_models/bb_trained.h5')


    def build_m11(self):
        ''' the dropout rates of 0.2, 0.3, 0.4 and batch normalization assigned between the convolution-pooling layers of VGG3, also the same added between the three fully connected layers of 4096 neurons each '''
        m11 = models.Sequential()
        #m11.add(layers.experimental.preprocessing.Rescaling(1/home/user/projects/255, input_shape=(self.image_width, self.image_height, 1)))

        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu',input_shape=(self.image_width, self.image_height, 1)))
        m11.add(layers.BatchNormalization())

        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.MaxPooling2D())
        m11.add(layers.Dropout(.2))

        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.MaxPooling2D())
        m11.add(layers.Dropout(.3, input_shape=(2,)))

        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Conv2D(32, 3, padding='same', activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.MaxPooling2D())
        m11.add(layers.Dropout(.4, input_shape=(2,)))

        m11.add(layers.Flatten())
        m11.add(layers.Dense(4096, activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Dropout(.2))
        m11.add(layers.Dense(4096, activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Dropout(.3, input_shape=(2,)))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Dense(4096, activation='relu'))
        m11.add(layers.BatchNormalization())
        m11.add(layers.Dropout(.4, input_shape=(2,)))
        m11.add(layers.Dense(1, activation='sigmoid'))
        return m11

    # memo - ref: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model
    '''def recall_m(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

    def precision_m(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

    def f1_m(y_true, y_pred):
        precision = precision_m(y_true, y_pred)
        recall = recall_m(y_true, y_pred)
        return 2*((precision*recall)/(precision+recall+K.epsilon()))'''


    def define_callbacks(self):

        checkpoint_cb = ModelCheckpoint("/home/user/projects/GAN_project/RESULTS/saved_models/bb_trained.h5", save_best_only=True)
        early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)
        logger_cb = CSVLogger('/home/user/projects/GAN_project/RESULTS/saved_models/logs/bb_training_log.csv', separator="|")
        return [checkpoint_cb, early_stopping_cb, logger_cb]

    def train_bb_detector(self,training_set,validation_set):
      
        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],run_eagerly = True)
        history = self.model.fit(training_set, epochs=self.epochs, validation_data=validation_set, shuffle=True,
                                 callbacks=self.define_callbacks())
        self.model.save('/home/user/projects/GAN_project/RESULTS/saved_models/bb_trained.h5')
        return history
    
    
    def plot_history(self):
      data_frame = pandas.DataFrame(self.history.history)
      data_frame.plot(figsize=(7, 3))
      plt.xlabel('Epochs')
      plt.ylabel('Sparse categorical cross-entropy')

    def evaluate_bb_detector(self,test_set):
      test_loss, test_acc, test_precision, test_recall = self.model.evaluate(test_set, verbose=2)
      print('\nTest loss:', test_loss)
      print('\nTest accuracy:', test_acc)
      print('\nTest precision:', test_precision)
      print('\nTest recall:', test_recall)


    def clear_folder(self,dir):
        for f in os.listdir(dir):
            os.remove(os.path.join(dir, f))
            
    def process_data(self, iterable, pred_epoch, result_dir):
        colormap = self.colormap 
        width = 512
        img_to_predict='/home/user/projects/dataset/mid_imgs/'
        self.clear_folder('/home/user/projects/dataset/mid_imgs/mid_imgs/')
        self.clear_folder('/home/user/projects/dataset/mid_no_cm/')
        
        i =0
        for it in iterable:
            img_bin_array = np.array(it).astype(int)
            #img_bin_array = it.reshape(it.shape[0]*it.shape[1]).astype(int)
            flat =img_bin_array.flatten()
            grayscale_array = ImageProcessing.to1DArray_grayscale(flat,colormap)
            height = math.ceil(len(grayscale_array)/width)
            height1 = math.ceil(len(flat)/width)
            if i<=9:
                ImageProcessing.saveImg('/home/user/projects/dataset/mid_imgs/mid_imgs/0'+str(i)+'.png', grayscale_array, (width,height),'L')
                if self.last_batch:
                    ImageProcessing.saveImg(result_dir + '/TR_NO_CM/'+'epoch_'+str(pred_epoch)+'_0'+str(i)+'.png', flat, (width,height1),'L')
                    ImageProcessing.saveImg(result_dir + '/TR_CM/'+'epoch_'+str(pred_epoch)+'_0'+str(i)+'.png', grayscale_array, (width,height),'L')
                    
            else:
                ImageProcessing.saveImg('/home/user/projects/dataset/mid_imgs/mid_imgs/'+str(i)+'.png', grayscale_array, (width,height),'L')
                #ImageProcessing.saveImg('training_results/TR_NO_CM/'+'epoch_'+str(pred_epoch)+' '+'_batch_'+str(self.last_batch)+'__'+str(i)+'.png', flat, (512,height1),'L')
                #ImageProcessing.saveImg('training_results/TR_CM/'+'epoch_'+str(pred_epoch)+' '+'_batch_'+str(self.last_batch)+'__'+str(i)+'.png', grayscale_array, (width,height),'L')
            i = i+1
        
        mid_img_set = self.upload_mid_set(img_to_predict)
        for only_batch in  mid_img_set:
            return only_batch  


    def upload_mid_set(self, DIRECTORY):
        COLOR_MODE = 'grayscale'
        IMAGE_HEIGHT = 256
        IMAGE_WIDTH = 256
        BATCH_SIZE = 64
        SEED = 1337
        mid_img_set= keras.preprocessing.image_dataset_from_directory(
            DIRECTORY,
            label_mode = None,
            color_mode=COLOR_MODE,
            seed=SEED,
            interpolation="area",
            batch_size=BATCH_SIZE,
            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),
            shuffle=False
        )
        return mid_img_set

    def make_prediction(self,samples, epoch, tr, result_dir):
        
        if tr == 4:
            self.last_batch = True
        else: 
            self.last_batch = False

        self.data = self.process_data(samples, epoch, result_dir)

        if self.loaded:
            return self.model.predict(self.data)
        else:
            return self.model.model(self.data)
